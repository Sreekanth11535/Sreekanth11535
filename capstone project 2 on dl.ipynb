{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecb1d8b0",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#  <center>CREDIT CARD FRAUD DETECTION USING MACHINE LEARNING METHODS</center>\n",
    "\n",
    " <p style=\"color:blue;\"- March 2020</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba95d59a",
   "metadata": {},
   "source": [
    "The datasets contains transactions made by credit cards in September 2013 by european cardholders.\n",
    "This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions. I decided to proceed to an undersampling strategy to re-balance the class.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4842d941",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8872/2459351246.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48990559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display all columns of the dataframe\n",
    "pd.options.display.max_columns = None\n",
    "# display all rows of the dataframe \n",
    "pd.options.display.max_rows = None\n",
    "# use below code to convert the 'exponential' values to float\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63671d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the plot size using 'rcParams'\n",
    "# once the plot size is set using 'rcParams', it sets the size of all the forthcoming plots in the file\n",
    "# pass width and height in inches to 'figure.figsize' \n",
    "plt.rcParams['figure.figsize'] = [15,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bf3dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('creditcard.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bde6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7963b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797f489b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d8c276",
   "metadata": {},
   "source": [
    "It seems duplicate data has beem removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5730ca63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdeed76",
   "metadata": {},
   "source": [
    "no null values found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab218978",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Time'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ffd389",
   "metadata": {},
   "source": [
    "Time is not significant in the dataset for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "893c0161",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "065ed511",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9460/1604108977.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#standard scaling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'std_Amount'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Amount'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#removing Amount\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Amount\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#standard scaling\n",
    "df['std_Amount'] = scaler.fit_transform(df['Amount'].values.reshape (-1,1))\n",
    "\n",
    "#removing Amount\n",
    "df = df.drop(\"Amount\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ffb910",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"Class\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba5d88a",
   "metadata": {},
   "source": [
    "The dataset is highly imbalanced ! \n",
    "It's a big problem because classifiers will always predict the most common class without performing any analysis of the features and it will have a high accuracy rate, obviously not the correct one. To change that, I will proceed to random undersampling.  \n",
    "\n",
    "The simplest undersampling technique involves randomly selecting examples from the majority class and deleting them from the training dataset. This is referred to as random undersampling.\n",
    "\n",
    "Although simple and effective, a limitation of this technique is that examples are removed without any concern for how useful or important they might be in determining the decision boundary between the classes. This means it is possible, or even likely, that useful information will be deleted.\n",
    "To undersample, we can use the package imblearn with RandomUnderSampler function !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8802b42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "\n",
    "undersample = RandomUnderSampler(sampling_strategy=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05c30e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns.tolist()\n",
    "cols = [c for c in cols if c not in [\"Class\"]]\n",
    "target = \"Class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cb29fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define X and Y\n",
    "X = df[cols]\n",
    "Y = df[target]\n",
    "\n",
    "#undersample\n",
    "X_under, Y_under = undersample.fit_resample(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f060c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "test = pd.DataFrame(Y_under, columns = ['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61d678e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing undersampling results\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(13,4.5))\n",
    "sns.countplot(x=\"Class\", data=df, ax=axs[0])\n",
    "sns.countplot(x=\"Class\", data=test, ax=axs[1])\n",
    "\n",
    "fig.suptitle(\"Class repartition before and after undersampling\")\n",
    "a1=fig.axes[0]\n",
    "a1.set_title(\"Before\")\n",
    "a2=fig.axes[1]\n",
    "a2.set_title(\"After(Test data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fae8bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_under, Y_under, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cb84fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e0702e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape=(29,), activation='relu')),\n",
    "model.add(Dropout(0.2)),\n",
    "model.add(Dense(16, activation='relu')),\n",
    "model.add(Dropout(0.2)),\n",
    "model.add(Dense(8, activation='relu')),\n",
    "model.add(Dropout(0.2)),\n",
    "model.add(Dense(4, activation='relu')),\n",
    "model.add(Dropout(0.2)),\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54d2b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001) #optimizer\n",
    "\n",
    "model.compile(optimizer=opt, loss=tf.keras.losses.BinaryCrossentropy(), metrics=['accuracy']) #metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdde995",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopper = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, patience=15, verbose=1,mode='auto', baseline=None, restore_best_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bbc836",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train.values, y_train.values, epochs = 6, batch_size=5, validation_split = 0.15, verbose = 0,\n",
    "                    callbacks = [earlystopper])\n",
    "history_dict = history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4b6682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce795b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
